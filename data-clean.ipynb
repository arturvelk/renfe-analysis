{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#read clean dataset\n",
    "data = pd.read_pickle(\"data/COR_MAD_all.pkl\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"Turista\": {\"Promo\": {\"price\": 39.3, \"seats\": 256}, \"Promo +\": {\"price\": 42.5, \"seats\": 256}, \"Flexible\": {\"price\": 63.4, \"seats\": 256}}, \"Preferente\": {\"Promo\": {\"price\": 66.2, \"seats\": 68}, \"Promo +\": {\"price\": 71.55, \"seats\": 68}, \"Flexible\": {\"price\": 106.8, \"seats\": 68}}}'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[301030, \"meta\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate train_id\n",
    "data[\"train_id\"] = data[[\"origin\", \"destination\", \"departure\",\"arrival\"]].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"weekday\"] = data[\"departure\"].apply(\n",
    "    lambda x: datetime.datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\").weekday()\n",
    ")\n",
    "data[\"depart_month\"] = data[\"departure\"].apply(\n",
    "    lambda x: datetime.datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\").month\n",
    ")\n",
    "data[\"depart_hour\"] = data[\"departure\"].apply(\n",
    "    lambda x: datetime.datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\").hour\n",
    ")\n",
    "# only jan, feb, march,\n",
    "data = data.loc[data[\"depart_month\"] < 4].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"depart_year\"] = data[\"departure\"].apply(\n",
    "    lambda x: datetime.datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\").year\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020    309944\n",
       "Name: depart_year, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"depart_year\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1409"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[\"train_id\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a price-seat adatok a meta változóban vannak,\n",
    "# ami egy mindig más struktúrájú dictionary,\n",
    "# elég trükkös volt kinyerni, arra írtam ezt a fgv-t\n",
    "\n",
    "\n",
    "def extract_meta(train):\n",
    "    prices_seats = pd.DataFrame()\n",
    "    for i in tqdm(range(train.shape[0])):\n",
    "        dic_in = json.loads(train.meta[i])\n",
    "        # extract values from tree dictionary\n",
    "        while type(list(dic_in.values())[0]) != float:\n",
    "            res = {key: list(value) for key, value in dic_in.items()}\n",
    "            dic_out = {}\n",
    "            for key in res.keys():\n",
    "                for value in res[key]:\n",
    "                    dic_out[key + \"_\" + value] = dic_in[key][value]\n",
    "            dic_in = dic_out\n",
    "\n",
    "        # check for seats, if no seat its the price\n",
    "        for key in list(dic_in.keys()):\n",
    "            if \"seats\" not in key:\n",
    "                if \"price\" not in key:\n",
    "                    dic_in[key + \"_price\"] = dic_in[key]\n",
    "                    dic_in.pop(key)\n",
    "\n",
    "        prices_seats = pd.concat(\n",
    "            [prices_seats, pd.DataFrame.from_dict(dic_in, orient=\"index\").T]\n",
    "        ).reset_index(drop=True)\n",
    "    return prices_seats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(309944, 19)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:43<00:00, 230.67it/s]\n",
      "100%|██████████| 10000/10000 [00:41<00:00, 239.42it/s]\n",
      "100%|██████████| 10000/10000 [00:40<00:00, 247.11it/s]\n",
      "100%|██████████| 10000/10000 [00:40<00:00, 248.91it/s]\n",
      "100%|██████████| 10000/10000 [00:46<00:00, 213.50it/s]\n",
      "100%|██████████| 10000/10000 [01:06<00:00, 149.82it/s]\n",
      "100%|██████████| 10000/10000 [01:06<00:00, 150.12it/s]\n",
      "100%|██████████| 10000/10000 [00:49<00:00, 201.70it/s]\n",
      "100%|██████████| 10000/10000 [00:58<00:00, 170.90it/s]\n",
      "100%|██████████| 10000/10000 [01:02<00:00, 160.03it/s]\n",
      "100%|██████████| 10000/10000 [01:16<00:00, 129.88it/s]\n",
      "100%|██████████| 10000/10000 [01:11<00:00, 139.37it/s]\n",
      "100%|██████████| 10000/10000 [01:09<00:00, 143.52it/s]\n",
      "100%|██████████| 10000/10000 [01:02<00:00, 159.58it/s]\n",
      "100%|██████████| 10000/10000 [01:00<00:00, 165.87it/s]\n",
      "100%|██████████| 10000/10000 [00:55<00:00, 181.58it/s]\n",
      "100%|██████████| 10000/10000 [01:58<00:00, 84.19it/s] \n",
      "100%|██████████| 10000/10000 [01:12<00:00, 137.84it/s]\n",
      "100%|██████████| 10000/10000 [01:01<00:00, 162.33it/s]\n",
      "100%|██████████| 10000/10000 [00:56<00:00, 177.53it/s]\n",
      "100%|██████████| 10000/10000 [00:48<00:00, 204.26it/s]\n",
      "100%|██████████| 10000/10000 [00:48<00:00, 204.81it/s]\n",
      "100%|██████████| 10000/10000 [00:45<00:00, 218.81it/s]\n",
      "100%|██████████| 10000/10000 [00:54<00:00, 182.11it/s]\n",
      "100%|██████████| 10000/10000 [00:49<00:00, 203.26it/s]\n",
      "100%|██████████| 10000/10000 [00:45<00:00, 220.44it/s]\n",
      "100%|██████████| 10000/10000 [00:45<00:00, 218.61it/s]\n",
      "100%|██████████| 10000/10000 [00:47<00:00, 210.86it/s]\n",
      "100%|██████████| 10000/10000 [00:42<00:00, 232.88it/s]\n",
      "100%|██████████| 10000/10000 [00:41<00:00, 242.95it/s]\n"
     ]
    }
   ],
   "source": [
    "chunks = {\n",
    "    i: pd.concat(\n",
    "        [\n",
    "            data.loc[i * 10000 : i * 10000 + 9999, :].reset_index(drop=True),\n",
    "            extract_meta(\n",
    "                data.loc[i * 10000 : i * 10000 + 9999, :].reset_index(drop=True)\n",
    "            ),\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "    for i in range(30)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(list(chunks.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9944/9944 [00:46<00:00, 211.83it/s]\n"
     ]
    }
   ],
   "source": [
    "last_chunk = pd.concat(\n",
    "    [\n",
    "        data.loc[300000:, :].reset_index(drop=True),\n",
    "        extract_meta(data.loc[300000:, :].reset_index(drop=True)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df,last_chunk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=[\"id\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'company', 'origin', 'destination', 'departure', 'arrival',\n",
       "       'duration', 'vehicle_type', 'vehicle_class', 'price', 'fare', 'seats',\n",
       "       'meta', 'insert_date', 'train_id', 'weekday', 'depart_month',\n",
       "       'depart_hour', 'depart_year', 'Turista_Flexible_price',\n",
       "       'Turista_Flexible_seats', 'Preferente_Flexible_price',\n",
       "       'Preferente_Flexible_seats', 'Turista_Promo_price',\n",
       "       'Turista_Promo_seats', 'Turista_Promo +_price', 'Turista_Promo +_seats',\n",
       "       'Preferente_Promo_price', 'Preferente_Promo_seats',\n",
       "       'Preferente_Promo +_price', 'Preferente_Promo +_seats',\n",
       "       'Turista Plus_Flexible_price', 'Turista Plus_Flexible_seats',\n",
       "       'Preferente_Mesa_price', 'Preferente_Mesa_seats', 'Turista_Mesa_price',\n",
       "       'Turista_Mesa_seats', 'Turista Plus_Promo_price',\n",
       "       'Turista Plus_Promo_seats', 'Turista Plus_Promo +_price',\n",
       "       'Turista Plus_Promo +_seats', 'Turista_Grupos Ida_price',\n",
       "       'Turista_Grupos Ida_seats', 'Preferente_Grupos Ida_price',\n",
       "       'Preferente_Grupos Ida_seats', 'Preferente_YOVOY_price',\n",
       "       'Preferente_YOVOY_seats'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\n",
    "    columns=[\n",
    "        \"Preferente_YOVOY_price\",\n",
    "        \"Preferente_YOVOY_seats\",\n",
    "        \"Turista_Grupos Ida_price\",\n",
    "        \"Turista_Grupos Ida_seats\",\n",
    "        \"Preferente_Grupos Ida_price\",\n",
    "        \"Preferente_Grupos Ida_seats\",\n",
    "        # \"Turista Plus_YOVOY_price\",\n",
    "        # \"Turista Plus_YOVOY_seats\",\n",
    "        # \"Turista_YOVOY VERANO_price\",\n",
    "        # \"Turista_YOVOY VERANO_seats\",\n",
    "        # \"Preferente_YOVOY VERANO_price\",\n",
    "        # \"Preferente_YOVOY VERANO_seats\",\n",
    "        # \"Turista Plus_YOVOY VERANO_price\",\n",
    "        # \"Turista Plus_YOVOY VERANO_seats\",\n",
    "        # \"Preferente_Mesa_seats\",\n",
    "        # \"Turista_Mesa_seats\",\n",
    "        # \"Turista Plus_Mesa_seats\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"days_till_dep\"] = [\n",
    "    (\n",
    "        datetime.datetime.strptime(df.loc[i, \"departure\"][0:19], \"%Y-%m-%d %H:%M:%S\")\n",
    "        - datetime.datetime.strptime(\n",
    "            df.loc[i, \"insert_date\"][0:19], \"%Y-%m-%d %H:%M:%S\"\n",
    "        )\n",
    "    ).days\n",
    "    for i in range(df.shape[0])\n",
    "]\n",
    "\n",
    "df[\"timedelta_till_dep\"] = [\n",
    "    (\n",
    "        datetime.datetime.strptime(df.loc[i, \"departure\"][0:19], \"%Y-%m-%d %H:%M:%S\")\n",
    "        - datetime.datetime.strptime(\n",
    "            df.loc[i, \"insert_date\"][0:19], \"%Y-%m-%d %H:%M:%S\"\n",
    "        )\n",
    "    )\n",
    "    for i in range(df.shape[0])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"data/COR_MAD_trains.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = pd.read_pickle(\"data/COR_MAD_trains.pkl\")\n",
    "data_2 = pd.read_pickle(\"data/MAD_COR_trains.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    \"origin\",\n",
    "    \"destination\",\n",
    "    \"departure\",\n",
    "    \"arrival\",\n",
    "    \"duration\",\n",
    "    \"insert_date\",\n",
    "    \"train_id\",\n",
    "    \"weekday\",\n",
    "    \"depart_month\",\n",
    "    \"depart_hour\",\n",
    "    \"depart_year\",\n",
    "    \"Turista_Promo_price\",\n",
    "    \"Turista_Promo +_price\",\n",
    "    \"Preferente_Promo_price\",\n",
    "    \"Preferente_Promo +_price\",\n",
    "    \"Turista Plus_Promo_price\",\n",
    "    \"Turista Plus_Promo +_price\",\n",
    "    \"Turista_Promo_seats\",\n",
    "    \"Turista_Promo +_seats\",\n",
    "    \"Preferente_Promo_seats\",\n",
    "    \"Preferente_Promo +_seats\",\n",
    "    \"Turista Plus_Promo_seats\",\n",
    "    \"Turista Plus_Promo +_seats\",\n",
    "    \"days_till_dep\",\n",
    "    \"timedelta_till_dep\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = pd.concat([data_1[columns], data_2[columns]]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all.to_pickle(\"data/COR_MAD_trains_clean.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
